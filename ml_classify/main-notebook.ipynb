{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e30535",
   "metadata": {},
   "source": [
    "<h2>Adding imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc13c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "from timeit import timeit\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "# matplotlib.use(\"pgf\")\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from joblib import dump, load\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import shap\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916b02cd",
   "metadata": {},
   "source": [
    "Open the dataset<br>\n",
    "The compile_dataset() function reads the dataset from file.<br>\n",
    "The original datasets contain these features:<br>\n",
    "timestamp/t (absolute), ID, DLC (some don't have this), data field 0, ..., data field 7, Label.<br>\n",
    "While compiling the dataset from the loaded files, new features are created.<br>\n",
    "From the timestamp, \"dt\" is created, and from timestamp and ID, \"dt_ID\" is created.<br>\n",
    "dt is the time between each CAN frame. dt_ID is the time between each CAN frame with the same ID.<br>\n",
    "From data field 0, ..., data field 7, \"ones\" is created, and from ID, \"ones_ID\" is created.<br>\n",
    "ones is the number of ones counted in the binary payload (combined data fields) for each CAN frame,<br>\n",
    "and ones_ID is the number of ones counted in the ID for each CAN frame.<br>\n",
    "Another feature, \"type\" is also added, which denotes the type of attack that a certain attack is.<br>\n",
    "For example, flooding (flood), and fuzzing (fuzz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3266ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from compiledataset import load_dataset, compile_dataset\n",
    "\n",
    "PATH = \"/home/hampus/miun/master_thesis/Datasets\"\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "# dataset: pd.DataFrame = load_dataset(PATH + \"/ORNL\", \"data_a.csv\")\n",
    "# dataset[\"remarks\"] = \"No DLC available\"\n",
    "# datasets[\"ROAD\"] = dataset.to_dict(\"records\")\n",
    "\n",
    "dataset: pd.DataFrame = load_dataset(PATH + \"/Survival\", \"data.csv\") #, \"FreeDrivingData_20180112_KIA\")\n",
    "dataset[\"remarks\"] = \"-\"\n",
    "datasets[\"Survival\"] = dataset.to_dict(\"records\")\n",
    "\n",
    "# dataset: pd.DataFrame = load_dataset(PATH + \"/Hisingen\", \"data.csv\")\n",
    "# dataset[\"remarks\"] = \"-\"\n",
    "# datasets[\"Hisingen\"] = dataset.to_dict(\"records\")\n",
    "\n",
    "\n",
    "df = compile_dataset(datasets)\n",
    "\n",
    "dataset = None # Release memory, as it isn't used for now\n",
    "datasets = None\n",
    "\n",
    "display(df[df[\"Label\"] == 1][[\"dt\", \"ID\", \"d0\", \"d1\", \"d2\", \"d3\", \"d4\", \"d5\", \"d6\", \"d7\"]])\n",
    "print(df[\"dt\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6887b9e7",
   "metadata": {},
   "source": [
    "Plots of the delta time of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a493dfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "# df[\"dt\"] *= 1000\n",
    "# df[\"t\"] -= 6e7\n",
    "# df = df.sample(frac=0.3, random_state=0)\n",
    "\n",
    "\n",
    "normal = df.loc[(df[\"Label\"] == 0), \"dt_ID\"]\n",
    "normal_t = df.loc[(df[\"Label\"] == 0), \"t\"]\n",
    "attack = df.loc[(df[\"Label\"] == 1), \"dt_ID\"]\n",
    "attack_t = df.loc[(df[\"Label\"] == 1), \"t\"]\n",
    "# print(len(attack))\n",
    "\n",
    "# normal = df.loc[(df[\"name\"] == \"Malfunction_dataset_SONATA\") & (df[\"Label\"] == 0), \"dcs\"]\n",
    "# normal_t = df.loc[(df[\"name\"] == \"Malfunction_dataset_SONATA\") & (df[\"Label\"] == 0), \"t\"]\n",
    "# attack = df.loc[(df[\"name\"] == \"Malfunction_dataset_SONATA\") & (df[\"Label\"] == 1), \"dcs\"]\n",
    "# attack_t = df.loc[(df[\"name\"] == \"Malfunction_dataset_SONATA\") & (df[\"Label\"] == 1), \"t\"]\n",
    "plt.figure(figsize=(9.6, 1.4), dpi=200)\n",
    "plt.gca().yaxis.set_major_formatter(StrMethodFormatter('{x:,.1f}'))\n",
    "plt.scatter(x=normal_t, y=normal*1000, s=0.5, label=\"Normal\")\n",
    "plt.scatter(x=attack_t, y=attack*1000, s=0.5, c=\"red\", label=\"Attack\")\n",
    "\n",
    "# plt.ylim(0, 10)\n",
    "\n",
    "plt.xlabel(\"Elapsed time (s)\")\n",
    "plt.ylabel(\"$\\Delta$ t (Âµs)\")\n",
    "plt.legend(markerscale=8, loc=\"upper right\")\n",
    "# plt.title(\"Chevrolet Spark\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig(\"ROAD_correlated_signal_attack_1_dt.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd1dc1b",
   "metadata": {},
   "source": [
    "Look at dt_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe9c706",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(\n",
    "    x=[\n",
    "        df.loc[df[\"Label\"] == 0, \"dt\"],\n",
    "        df.loc[df[\"type\"] == \"masq\", \"dt\"],\n",
    "        df.loc[df[\"type\"] == \"fuzz\", \"dt\"],\n",
    "        df.loc[df[\"type\"] == \"fabr\", \"dt\"]\n",
    "    ],\n",
    "    bins=100,\n",
    "    range=(0, 0.01),\n",
    "    color=[\"tab:blue\", \"tab:red\", \"tab:green\", \"tab:purple\"],\n",
    "    log=True,\n",
    "    label=[\"Normal\", \"masq\", \"fuzz\", \"fabr\"], histtype=\"step\"\n",
    ")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time between packets with the same ID\\n(Divided into 100 steps)\")\n",
    "plt.ylabel(\"Number of CAN frames\")\n",
    "# plt.hist(df.loc[df[\"Label\"] == 1, \"dt_ID\"], bins=30, range=(0, 50), color=\"tab:red\", log=True, rwidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f233a90b",
   "metadata": {},
   "source": [
    "Measure the occurence of IDs in the normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f719f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "types, types_count = np.unique(df.loc[df[\"Label\"] == 0, \"ID\"], return_counts=True)\n",
    "t_dt = []\n",
    "for t in types:\n",
    "    t_dt.append(df.loc[(df[\"ID\"] == t) & (df[\"Label\"] == 0), \"dt_ID\"].mean())\n",
    "plt.bar(x=types, height=t_dt)#, log=True)\n",
    "plt.show()\n",
    "print(df[\"dt_ID\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4090211e",
   "metadata": {},
   "source": [
    "Drop a few columns<br>\n",
    "The data fields are dropped because there are different standards for each car manufacturers<br>\n",
    "on how to use the bytes in the payload of the CAN frame.<br>\n",
    "The ID is dropped for the same reason as the data fields; manufacturers use different high level protocols<br>\n",
    "to encode the ID field in their vehicles. Also, some datasets obfuscate their data.\n",
    "DLC is dropped because it does not exist in all datasets.<br>\n",
    "t is dropped because the absolute timestamps will not give much information, because<br>\n",
    "data dathered on different times will vary a lot. The delta time (dt) is better in this regard.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4422006",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"d0\", \"d1\", \"d2\", \"d3\", \"d4\", \"d5\", \"d6\", \"d7\", \"ID\", \"DLC\", \"t\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a8ce46",
   "metadata": {},
   "source": [
    "Perform a Chi Squared test to see if there are any features that aren't dependent on the classification label, \"Label\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2730c0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a dataframe without \"type\", as it is categorical and will not be used to train later\n",
    "# Drop dt and dt_ID as they are not categorical\n",
    "X_chi = df.drop(columns=[\"dt\" ,\"dt_ID\", \"type\", \"dataset\", \"Label\"])\n",
    "y_chi = df[\"Label\"]\n",
    "chi_scores = chi2(X_chi, y_chi)\n",
    "p_values = chi_scores[1]\n",
    "print(p_values)\n",
    "plt.bar(x=X_chi.columns, height=p_values)\n",
    "plt.show()\n",
    "X_chi = None # Release memory\n",
    "y_chi = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fb40fc",
   "metadata": {},
   "source": [
    "I believe this means there is not sufficient evidence to disprove the null hypothesis (i.e. that features are independent of class label)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf66664",
   "metadata": {},
   "source": [
    "We can also check the correlation between the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411bc160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = df.drop(columns=[\"dataset\", \"type\"]).corr()\n",
    "\n",
    "# Drop first row and last column that don't provide information\n",
    "corr.drop(index=corr.index[0], inplace=True)\n",
    "corr.drop(columns=corr.columns[-1], inplace=True)\n",
    "\n",
    "# Generate a mask for the upper triangle but not the diagonal\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "np.fill_diagonal(mask, False)\n",
    "\n",
    "# Draw the correlation heatmap with the mask\n",
    "def tostr(num):\n",
    "    if isinstance(num, str): return num\n",
    "    if num < 0: return str(num)[:5]\n",
    "    return str(num)[:4]\n",
    "def remove_nocorr(corr):\n",
    "    annot = corr.copy()\n",
    "    annot.where(np.abs(annot) > 0.1, \" \", inplace=True)\n",
    "    annot = annot.applymap(tostr)\n",
    "    return annot\n",
    "annots = remove_nocorr(corr)\n",
    "\n",
    "sns.heatmap(corr, mask=mask, vmin=-1, vmax=1, center=0, annot=annots, annot_kws={\"fontsize\": 8}, fmt=\"s\", square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f864782c",
   "metadata": {},
   "source": [
    "We will now see if the dataset is imbalanced, and also how we should stratify when creating the training and test sets.<br>\n",
    "Stratification makes sure that there is the same proportion of a class in both the training and test sets.<br>\n",
    "If the whole dataset contains 1% of one class and 99% of another, then the training and test sets will also have that proportion.<br>\n",
    "We begin by looking at the proportion of Normal vs Attack instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb897c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x=[\"Normal\", \"Attack\"], height=np.bincount(df[\"Label\"]), color=[\"tab:blue\", \"tab:red\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d785bb",
   "metadata": {},
   "source": [
    "Next, we look at the proportion of the different types of attacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7084bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "types, types_count = np.unique(df.loc[df[\"type\"] != \"none\", \"type\"], return_counts=True)\n",
    "plt.bar(x=types, height=types_count, color=[\"tab:green\", \"tab:red\", \"tab:orange\", \"tab:blue\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b163b7ca",
   "metadata": {},
   "source": [
    "It can be seen that there are different amounts of attack types in the dataset.<br>\n",
    "We want the proportion to be the same after splitting into training and testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330800c6",
   "metadata": {},
   "source": [
    "Visualize the distribution of attack instances by ones counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0711fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_temp = pd.concat([X_train, y_train], axis=\"columns\")\n",
    "size = len(df.loc[df[\"Label\"] == 1].index)\n",
    "ones_prob = [[], [], []]\n",
    "# zeros_prob = []\n",
    "for i in range(65):\n",
    "    # zeros_prob.append(len(d_temp.loc[(d_temp[\"Label\"] == 0) & (d_temp[\"ones\"] == i)].index) / size)\n",
    "\n",
    "    prob_flood = len(df.loc[(df[\"Label\"] == 1) & (df[\"ones\"] == i) & (df[\"type\"] == \"masq\")].index) / size\n",
    "    prob_fuzz = len(df.loc[(df[\"Label\"] == 1) & (df[\"ones\"] == i) & (df[\"type\"] == \"fuzz\")].index) / size\n",
    "    prob_fabr = len(df.loc[(df[\"Label\"] == 1) & (df[\"ones\"] == i) & (df[\"type\"] == \"fabr\")].index) / size\n",
    "    ones_prob[0].append(prob_flood)\n",
    "    ones_prob[1].append(prob_fuzz)\n",
    "    ones_prob[2].append(prob_fabr)\n",
    "\n",
    "\n",
    "# zeros_prob = pd.Series(zeros_prob)\n",
    "ones_prob = pd.Series(ones_prob)\n",
    "# sns.lineplot(data=ones_prob)\n",
    "\n",
    "# plt.bar(x=range(0, 65), height=zeros_prob)\n",
    "plt.bar(x=range(0, 65), height=ones_prob[0], color=\"tab:red\")\n",
    "plt.bar(x=range(0, 65), height=ones_prob[1], color=\"tab:green\")\n",
    "plt.bar(x=range(0, 65), height=ones_prob[2], color=\"tab:orange\")\n",
    "plt.legend(labels=[\"Flooding\", \"Fuzzing\", \"Fabrication\"])\n",
    "plt.xlabel(\"Number of ones counted\")\n",
    "plt.ylabel(\"% of attack observations (Label = 1)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8d56e7",
   "metadata": {},
   "source": [
    "It shows that in the flooding attack, there is never any ones, and it makes up almost 50% of all attacks.<br>\n",
    "It also shows that the fuzzing attack is randomly generating payloads (as is stated in the paper as well), and since there is a higher chance that a payload will have a one count of 32 (by binomial distribution) the distribution looks the way it does.<br>\n",
    "It shows that the fabrication attacks have 20 ones, 29 ones or randomly chose (it is the same as fuzzing, just smaller so is not seen well on the graph, but it is seen if plotted separately.).<br>\n",
    "It shows that 50% of the attacks contain no ones in the payload, so you will catch many attacks going just on that!\n",
    "Moreover, these attacks have clear patterns by how many ones they contain, as they are either a Specific value (0, 20 or 29).. or... binomially distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcce076",
   "metadata": {},
   "source": [
    "Create the training and test data (with stratification on the type of attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d2c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop(columns=\"type\")\n",
    "y_train = df[\"type\"]\n",
    "\n",
    "df = None # Release memory\n",
    "\n",
    "# Split dataset into training and test data, stratify by the type of attack\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.3, random_state=0, shuffle=True, stratify=y_train)\n",
    "\n",
    "# # Under-sample on type\n",
    "# rus = RandomUnderSampler(random_state=0)\n",
    "# X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Use feature \"Label\" as classification label\n",
    "d_temp: pd.DataFrame = pd.concat([X_train, y_train], axis=\"columns\")\n",
    "X_train, y_train = d_temp.drop(columns=\"Label\"), d_temp[\"Label\"]\n",
    "d_temp: pd.DataFrame = pd.concat([X_test, y_test], axis=\"columns\")\n",
    "X_test, y_test = d_temp.drop(columns=\"Label\"), d_temp[\"Label\"]\n",
    "d_temp = None # Release memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e38bb",
   "metadata": {},
   "source": [
    "Now, we can look at the proportions again (in the Training data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140f4e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "types, types_count = np.unique(X_train.loc[X_train[\"type\"] != \"none\", \"type\"], return_counts=True)\n",
    "plt.bar(x=types, height=types_count, color=[\"tab:orange\", \"tab:red\", \"tab:green\", \"tab:blue\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a97c37",
   "metadata": {},
   "source": [
    "Under-sample the training set by the majority class (no attack, 0). The test set can be left imbalanced, as real world data can also be imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d6cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "bintr = np.bincount(y_train)\n",
    "binte = np.bincount(y_test)\n",
    "print(f\"Labels\\t\\tTraining\\tTesting\\nNormal\\t\\t{bintr[0]}\\t\\t{binte[0]}\\nAttack\\t\\t{bintr[1]}\\t\\t{binte[1]}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cc1c01a394bbc3d069051c289161a3236732c38d026dbad3d7b5639e0cadb70"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ml-classify-pJEs0r8S-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
