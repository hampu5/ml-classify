{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "from timeit import timeit\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from joblib import dump, load\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compiledataset import load_dataset, compile_dataset\n",
    "\n",
    "PATH = \"/home/hampus/miun/master_thesis/Datasets\"\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "# dataset: pd.DataFrame = load_dataset(PATH + \"/ORNL\", \"data_a.csv\")\n",
    "# dataset[\"remarks\"] = \"No DLC available\"\n",
    "# datasets[\"ROAD\"] = dataset.to_dict(\"records\")\n",
    "\n",
    "# dataset: pd.DataFrame = load_dataset(PATH + \"/Survival\", \"data.csv\") #, \"Malfunction_dataset_SONATA\")\n",
    "# dataset[\"remarks\"] = \"-\"\n",
    "# datasets[\"Survival\"] = dataset.to_dict(\"records\")\n",
    "\n",
    "# dataset: pd.DataFrame = load_dataset(PATH + \"/Hisingen\", \"data.csv\", \"Vehicle_F-Model_2-Fabrication_attack-Sample_1\")\n",
    "# dataset[\"remarks\"] = \"-\"\n",
    "# datasets[\"Hisingen\"] = dataset.to_dict(\"records\")\n",
    "\n",
    "\n",
    "# df = compile_dataset(datasets)\n",
    "\n",
    "df: pd.DataFrame = load(\"dumped_datasets/survival_all.joblib\")\n",
    "# df: pd.DataFrame = load(\"dumped_datasets/road_all.joblib\")\n",
    "# df: pd.DataFrame = load(\"dumped_datasets/hisingen_all.joblib\")\n",
    "\n",
    "df.drop(columns=[\"data\", \"data_dec\", \"ID\", \"DLC\", \"t\"], inplace=True, errors=\"ignore\")\n",
    "df.drop(columns=[\"d0\", \"d1\", \"d2\", \"d3\", \"d4\", \"d5\", \"d6\", \"d7\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "dataset = None # Release memory, as it isn't used for now\n",
    "datasets = None\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratify on the sub-dataset\n",
    "X_train = df.drop(columns=\"Label\")\n",
    "y_train = df[\"Label\"]\n",
    "\n",
    "df = None # Release memory\n",
    "\n",
    "# Split dataset into training and test data, stratify by the type of attack\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.3, random_state=0, shuffle=True, stratify=X_train[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "X_test, y_test = rus.fit_resample(X_test, y_test)\n",
    "bintr = np.bincount(y_train)\n",
    "binte = np.bincount(y_test)\n",
    "print(f\"Labels\\t\\tTraining\\tTesting\\nNormal\\t\\t{bintr[0]}\\t\\t{binte[0]}\\nAttack\\t\\t{bintr[1]}\\t\\t{binte[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_train = X_train[\"name\"]\n",
    "# name_test = X_test[\"name\"]\n",
    "X_train.drop(columns=[\"type\", \"dataset\", \"name\", \"class\"], inplace=True)\n",
    "X_test.drop(columns=[\"type\", \"dataset\", \"name\", \"class\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lm = LogisticRegression(random_state=0)\n",
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores_train = cross_val_score(lm, X_train, y_train, scoring='f1', cv=10, n_jobs=-1)\n",
    "print(\"Training F1: %0.4f (+/- %0.4f)\" % (f1_scores_train.mean(), f1_scores_train.std()))\n",
    "\n",
    "# f1_scores_test = f1_score(y_test, pred, average='weighted')\n",
    "f1_scores_test = cross_val_score(lm, X_test, y_test, scoring='f1', cv=10, n_jobs=-1)\n",
    "print(\"Testing F1:  %0.4f (+/- %0.4f)\" % (f1_scores_test.mean(), f1_scores_test.std()))\n",
    "\n",
    "pred = lm.predict(X_test)\n",
    "\n",
    "kappa_scores = cohen_kappa_score(y_test, pred)\n",
    "# kappa_scores = cross_val_score(clf, X_test, y_test, scoring='kappa', cv=10, n_jobs=-1)\n",
    "print(\"Kappa score:  %0.4f\" % (kappa_scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_tools import plot_confusion_matrix\n",
    "\n",
    "pred_train = lm.predict(X_train)\n",
    "\n",
    "plot_confusion_matrix(y_train, pred_train, \"RF, \\\"Survival\\\", all attacks, training data\\n(# of instances)\", cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, pred, \"RF, \\\"Survival\\\", all attacks, testing data\\n(# of instances)\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cc1c01a394bbc3d069051c289161a3236732c38d026dbad3d7b5639e0cadb70"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ml-classify-pJEs0r8S-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
