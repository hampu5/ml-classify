{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "from timeit import timeit\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from joblib import dump, load\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compiledataset import load_dataset, compile_dataset\n",
    "\n",
    "PATH = \"/home/hampus/miun/master_thesis/Datasets\"\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "# dataset: pd.DataFrame = load_dataset(PATH + \"/ORNL\", \"data_a.csv\")\n",
    "# dataset[\"remarks\"] = \"No DLC available\"\n",
    "# datasets[\"ROAD\"] = dataset.to_dict(\"records\")\n",
    "\n",
    "# dataset: pd.DataFrame = load_dataset(PATH + \"/Survival\", \"data.csv\") #, \"Malfunction_dataset_SONATA\")\n",
    "# dataset[\"remarks\"] = \"-\"\n",
    "# datasets[\"Survival\"] = dataset.to_dict(\"records\")\n",
    "\n",
    "# dataset: pd.DataFrame = load_dataset(PATH + \"/Hisingen\", \"data.csv\", \"Vehicle_F-Model_2-Fabrication_attack-Sample_1\")\n",
    "# dataset[\"remarks\"] = \"-\"\n",
    "# datasets[\"Hisingen\"] = dataset.to_dict(\"records\")\n",
    "\n",
    "\n",
    "# df = compile_dataset(datasets)\n",
    "\n",
    "# df: pd.DataFrame = load(\"dumped_datasets/survival_all.joblib\")\n",
    "df: pd.DataFrame = load(\"dumped_datasets/road_all.joblib\")\n",
    "# df: pd.DataFrame = load(\"dumped_datasets/hisingen_all.joblib\")\n",
    "\n",
    "# df.drop(columns=[\"dcs\", \"dt\", \"dt_data\"], inplace=True, errors=\"ignore\")\n",
    "df.drop(columns=[\"data\", \"data_dec\", \"ID\", \"DLC\", \"t\"], inplace=True, errors=\"ignore\")\n",
    "df.drop(columns=[\"d0\", \"d1\", \"d2\", \"d3\", \"d4\", \"d5\", \"d6\", \"d7\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "dataset = None # Release memory, as it isn't used for now\n",
    "datasets = None\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df[\"type\"] != \"masq\"]\n",
    "# df = df.loc[(df[\"type\"] == \"fuzz\") | (df[\"type\"] == \"none\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# X_train_original = df.copy()\n",
    "\n",
    "# feature_columns= list(set(df.columns.to_list()).difference([\"name\", \"class\", \"dataset\", \"type\", \"Label\"]))\n",
    "\n",
    "# for col in feature_columns:\n",
    "#     scaler = RobustScaler().fit(df.loc[df[\"Label\"] == 0, df.columns == col])\n",
    "#     df.loc[:, df.columns == col] = scaler.transform(df.loc[:, df.columns == col])\n",
    "\n",
    "# from pp_tools import scale_dataset\n",
    "# df_original = df.drop(columns=[\"type\", \"dataset\", \"name\", \"class\", \"Label\"]).copy()\n",
    "# scale_dataset(df)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop(columns=\"Label\")\n",
    "y_train = df[\"Label\"]\n",
    "\n",
    "df = None # Release memory\n",
    "\n",
    "# Split dataset into training and test data, stratify by the name of the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.3, random_state=0, shuffle=True, stratify=X_train[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rus = RandomUnderSampler(random_state=0)\n",
    "# X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "# X_test, y_test = rus.fit_resample(X_test, y_test)\n",
    "# bintr = np.bincount(y_train)\n",
    "# binte = np.bincount(y_test)\n",
    "# print(f\"Labels\\t\\tTraining\\tTesting\\nNormal\\t\\t{bintr[0]}\\t\\t{binte[0]}\\nAttack\\t\\t{bintr[1]}\\t\\t{binte[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=[\"type\", \"dataset\", \"name\", \"class\"], inplace=True, errors=\"ignore\")\n",
    "X_test.drop(columns=[\"type\", \"dataset\", \"name\", \"class\"], inplace=True, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pp_tools import scale_dataset\n",
    "\n",
    "X_train_original = X_train.copy()\n",
    "X_test_original = X_test.copy()\n",
    "\n",
    "X_combined = pd.concat([X_train, X_test])\n",
    "\n",
    "scale_dataset(X_combined)\n",
    "\n",
    "test_len = len(X_test)\n",
    "X_test = X_combined.iloc[-test_len:]\n",
    "X_train = X_combined.iloc[:-test_len]\n",
    "\n",
    "X_combined = None # Release memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "# dnn = keras.models.Sequential(\n",
    "#     [\n",
    "#         keras.Input(shape=(len(X_train.columns),), name=\"input\"),\n",
    "#         layers.Dense(11, activation='relu', name=\"layer_1\", kernel_initializer=\"glorot_normal\"),\n",
    "#         layers.Dense(23, activation='relu', name=\"layer_2\", kernel_initializer=\"glorot_normal\"),\n",
    "#         layers.Dense(7, activation='relu', name=\"layer_3\", kernel_initializer=\"glorot_normal\"),\n",
    "#         layers.Dense(1, activation='sigmoid', name=\"output\", kernel_initializer=\"glorot_normal\")\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# dnn.compile(\n",
    "#     optimizer=\"adam\",  # Optimizer rmsprop\n",
    "#     # Loss function to minimize\n",
    "#     loss=keras.losses.BinaryCrossentropy(),\n",
    "#     # List of metrics to monitor\n",
    "#     metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.Recall(), keras.metrics.FalseNegatives()],\n",
    "# )\n",
    "\n",
    "dnn = keras.models.load_model(\"dnn_all_road_imbalanced\")\n",
    "\n",
    "# val_percent = int(len(y_train) * 0.1)\n",
    "# X_val = X_train.sample(val_percent, random_state=0)\n",
    "# y_val = y_train.loc[X_val.index]\n",
    "# X_train = X_train.loc[~X_train.index.isin(X_val)]\n",
    "# y_train = y_train.loc[~y_train.index.isin(X_val)]\n",
    "\n",
    "# from sklearn.utils import class_weight\n",
    "# class_weights = class_weight.compute_class_weight(\"balanced\", classes=np.unique(y_train), y=y_train)\n",
    "# class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# def create_class_weight(labels_dict, mu=0.15):\n",
    "#     total = np.sum(list(labels_dict.values()))\n",
    "#     keys = labels_dict.keys()\n",
    "#     class_weight = dict()\n",
    "    \n",
    "#     for key in keys:\n",
    "#         score = math.log(mu*total/float(labels_dict[key]))\n",
    "#         class_weight[key] = score if score > 1.0 else 1.0\n",
    "    \n",
    "#     return class_weight\n",
    "\n",
    "# dnn.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     batch_size=200,\n",
    "#     epochs=20,\n",
    "#     class_weight=class_weights,\n",
    "#     validation_data=(X_val, y_val),\n",
    "#     callbacks=[keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)]\n",
    "# )\n",
    "\n",
    "# dnn.save(\"dnn_all_road_imbalanced\")\n",
    "\n",
    "# results = dnn.evaluate(X_test, y_test, batch_size=128)\n",
    "# print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score, f1_score, accuracy_score, matthews_corrcoef\n",
    "\n",
    "pred_train = np.round(dnn.predict(X_train))\n",
    "\n",
    "f1_scores = f1_score(y_train, pred_train, average='weighted')\n",
    "print(\"Training F1:  %0.4f (+/- %0.4f)\" % (f1_scores.mean(), f1_scores.std()))\n",
    "\n",
    "proba_test = dnn.predict(X_test)\n",
    "pred_test = np.round(proba_test)\n",
    "\n",
    "\n",
    "\n",
    "acc_scores = accuracy_score(y_test, pred_test)\n",
    "print(\"Testing Accuracy:  %0.4f (+/- %0.4f)\" % (acc_scores.mean(), acc_scores.std()))\n",
    "\n",
    "f1_scores = f1_score(y_test, pred_test, average='weighted')\n",
    "print(\"Testing F1:  %0.4f (+/- %0.4f)\" % (f1_scores.mean(), f1_scores.std()))\n",
    "\n",
    "matt_scores = matthews_corrcoef(y_test, pred_test)\n",
    "print(\"Testing Matthews corr:  %0.4f (+/- %0.4f)\" % (matt_scores.mean(), matt_scores.std()))\n",
    "\n",
    "kappa_scores = cohen_kappa_score(y_test, pred_test)\n",
    "print(\"Kappa score:  %0.4f(+/- %0.4f)\" % (kappa_scores.mean(), kappa_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_tools import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(y_train, pred_train, \"DNN, \\\"Survival\\\", all attacks, training data\\n(# of instances)\", cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, pred_test, \"DNN, \\\"Survival\\\", all attacks, testing data\\n(# of instances)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, pred_test, normalize=\"true\"))\n",
    "print(confusion_matrix(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, proba_test, name=\"DNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "exp = shap.KernelExplainer(dnn, data=X_train.sample(100, random_state=1))\n",
    "print(exp.expected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shap_tools import *\n",
    "\n",
    "X_exp = X_train.sample(min(len(X_train), 600), random_state=0)\n",
    "y_exp = y_train[X_exp.index]\n",
    "X_exp_original = X_train_original.loc[X_exp.index]\n",
    "# print(X_exp)\n",
    "# print(X_exp_original)\n",
    "\n",
    "# Make sure that the ingested SHAP model (a TreeEnsemble object) makes the\n",
    "# same predictions as the original model\n",
    "# assert np.abs(exp.model.predict(X_exp) - dnn.predict_proba(X_exp)).max() < 1e-4\n",
    "\n",
    "\n",
    "# # Make sure the SHAP values sum up to the model output (this is the local accuracy property)\n",
    "# assert np.abs((shap_all.base_values + shap_all.values).sum(1) - clf.predict_proba(X_train)).max() < 1e-4\n",
    "\n",
    "# print(len(X_train.loc[y_train != pred]))\n",
    "# print(len(X_train.loc[y_train == pred]))\n",
    "# shap_false = get_explanation(exp, X_train.loc[y_train != pred])\n",
    "# shap_FP = get_explanation(exp, X_train.loc[(y_train != pred) & (pred == 1)])\n",
    "# shap_FN = get_explanation(exp, X_train.loc[(y_train != pred) & (pred == 0)])\n",
    "# shap_true = get_explanation(exp, X_train.loc[y_train == pred])\n",
    "# shap_TP = get_explanation(exp, X_train.loc[(y_train == pred) & (pred == 1)])\n",
    "# shap_TN = get_explanation(exp, X_train.loc[(y_train == pred) & (pred == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_all = get_explanation(exp, X_exp)\n",
    "# dump(shap_all, \"dnn_survival_all_shap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_check = X_test_original.sample(10, random_state=18)\n",
    "y_test_check = y_test.loc[X_test_check.index]\n",
    "pred_check = pred_test[X_test_check.index].T[0]\n",
    "\n",
    "df_check = X_test_check\n",
    "df_check[\"Label\"] = pred_check\n",
    "df_check[\"Label\"] = df_check[\"Label\"].astype(np.int64)\n",
    "df_check[\"Label\"].replace({0: \"normal\", 1: \"attack\"}, inplace=True)\n",
    "df_check.rename(columns = {'dcs_ID': 'A', 'dt_ID': 'B'}, inplace = True)\n",
    "df_check = df_check.reset_index()\n",
    "df_check[\"A\"] = df_check[\"A\"].apply(lambda x: round(x, 3))\n",
    "df_check[\"B\"] = df_check[\"B\"].apply(lambda x: round(x*1000, 2))\n",
    "# df_check = pd.DataFrame(df_check[[\"dcs_ID\", \"dt_ID\"]], )\n",
    "# pred_check = pd.Series(pred_check, name=\"Label\")\n",
    "\n",
    "\n",
    "display(df_check[[\"A\", \"B\", \"Label\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sample = X_test_original.sample(10, random_state=11)\n",
    "y_test_sample = y_test.loc[X_test_sample.index]\n",
    "pred_sample = pred_test[X_test_sample.index].T\n",
    "print(X_test_sample)\n",
    "print(y_test_sample)\n",
    "print(pred_sample)\n",
    "\n",
    "# 0     10    0\n",
    "# 0.031 10    0\n",
    "# 0.015 20    0\n",
    "# 0.3   1     1\n",
    "# 0     0.56  1\n",
    "# 0     12    0\n",
    "# 0.031 20    0\n",
    "# 0     2.4   1\n",
    "# 0.45  180   1\n",
    "# 0.61  1500  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_all.feature_names = [\"T\", \"A\", \"C\", \"B\", \"E\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_beeswarm(shap_all)\n",
    "def plot_beeswarm2(exp_obj):\n",
    "    vis = shap.plots.beeswarm(exp_obj, show=False, max_display=20, color=plt.get_cmap(\"plasma\"), order=[1, 3], color_bar=False)\n",
    "    # plt.gcf().axes[-1].set_aspect(100)\n",
    "    # plt.gcf().axes[-1].set_box_aspect(100)\n",
    "    cbar = plt.colorbar(plt.cm.ScalarMappable(cmap=\"plasma\"), label=\"Feature value\")\n",
    "    cbar.set_ticks([0, 1])\n",
    "    cbar.set_ticklabels([\"Low\", \"High\"])\n",
    "    plt.xlabel(\"<- towards normal | towards attack ->\")\n",
    "    return vis\n",
    "\n",
    "plot_beeswarm2(shap_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "def cust_exp(df_exp: pd.DataFrame, shap_all: shap.Explanation, feature, scale):\n",
    "    df_exp[\"Label\"].replace({0: \"normal\", 1: \"attack\"}, inplace=True)\n",
    "    shap_exp = shap_all.values[:,df_exp.columns.get_loc(feature)]\n",
    "\n",
    "    mask = (df_exp[feature] >= scale[0]) & (df_exp[feature] < scale[1])\n",
    "\n",
    "    attack_outliers = shap_exp[~mask & (df_exp[\"Label\"] == \"attack\")]\n",
    "    normal_outliers = shap_exp[~mask & (df_exp[\"Label\"] == \"normal\")]\n",
    "\n",
    "    shap_exp = shap_exp[mask]\n",
    "    df_exp = df_exp[mask].copy()\n",
    "    \n",
    "    scaler = max(abs(shap_exp.min()), abs(shap_exp.max()))\n",
    "    shap_hues = shap_exp / scaler\n",
    "    shap_hues = (shap_hues + 1) * shap_all.base_values[0]\n",
    "\n",
    "    cmap = sns.color_palette(\"icefire\", as_cmap=True)\n",
    "    norm = plt.Normalize(vmin=0, vmax=1)\n",
    "    palette = {h: cmap(h) for h in shap_hues}\n",
    "\n",
    "    df_exp[\"shap_hues\"] = shap_hues\n",
    "    \n",
    "    normal_values = df_exp.loc[df_exp[\"Label\"] == \"normal\", [feature, \"shap_hues\"]]\n",
    "    attack_values = df_exp.loc[df_exp[\"Label\"] == \"attack\", [feature, \"shap_hues\"]]\n",
    "    \n",
    "    normal_hist, normal_bins = np.histogram(normal_values[feature], bins=50, range=(scale[0], scale[1]))\n",
    "    attack_hist, attack_bins = np.histogram(attack_values[feature], bins=50, range=(scale[0], scale[1]))\n",
    "\n",
    "    fig, ax = plt.subplots(dpi=100, figsize=(10, 1))\n",
    "    \n",
    "    max_bar = max(normal_hist.max(), attack_hist.max())\n",
    "    normal_hist = normal_hist / max_bar\n",
    "    attack_hist = attack_hist / max_bar\n",
    "\n",
    "    normal_cont = ax.bar(normal_bins[:-1], normal_hist, width=(scale[1] - scale[0])/50, align=\"edge\")\n",
    "    attack_cont = ax.bar(attack_bins[:-1], -attack_hist, width=(scale[1] - scale[0])/50, align=\"edge\")\n",
    "\n",
    "\n",
    "    # display(normal_values)\n",
    "    prev_edge = 0\n",
    "    for i in range(1, len(normal_bins)):\n",
    "        normal_hues_mean = normal_values.loc[(normal_values[feature] >= normal_bins[prev_edge]) & (normal_values[feature] < normal_bins[i]), \"shap_hues\"].fillna(0.5).mean()\n",
    "        attack_hues_mean = attack_values.loc[(attack_values[feature] >= attack_bins[prev_edge]) & (attack_values[feature] < attack_bins[i]), \"shap_hues\"].fillna(0.5).mean()\n",
    "\n",
    "        # print(shap_hues_mean)\n",
    "        normal_cont.patches[i - 1].set_facecolor(cmap(normal_hues_mean))\n",
    "        attack_cont.patches[i - 1].set_facecolor(cmap(attack_hues_mean))\n",
    "        # attack_cont.patches[i - 1]\n",
    "\n",
    "        prev_edge = i\n",
    "\n",
    "    tick_unit = (scale[1] - scale[0]) / 10\n",
    "    ax.set_xlim(scale[0] - 0.5*tick_unit, scale[1] + 0.5*tick_unit)\n",
    "    ax.set_xticks(ticks=np.linspace(scale[0], scale[1], 11)) #, labels=map(lambda x: format(x, '.2f'), np.linspace(0, 0.02, 11)))\n",
    "    ax.set_ylim(-1, 1)\n",
    "    ax.set_yticks(ticks=[-0.5, 0.5], labels=[\"attack\", \"normal\"])\n",
    "\n",
    "    ax.axhline(y=0, color=\"black\", linewidth=0.5, zorder=-1)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "cust_exp(pd.concat([X_exp_original, y_exp], axis=1), shap_all, \"dcs\", scale=(0, 1))\n",
    "cust_exp(pd.concat([X_exp_original, y_exp], axis=1), shap_all, \"dcs_ID\", scale=(0, 1))\n",
    "cust_exp(pd.concat([X_exp_original, y_exp], axis=1), shap_all, \"dt\", scale=(0, 0.0003))\n",
    "cust_exp(pd.concat([X_exp_original, y_exp], axis=1), shap_all, \"dt_ID\", scale=(0, 0.02))\n",
    "cust_exp(pd.concat([X_exp_original, y_exp], axis=1), shap_all, \"dt_data\", scale=(0, 0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "def plot_test(df_exp: pd.DataFrame, shap_all: shap.Explanation, feature, trim=None, y_squish=10, scale=1, colorbar=False, y_size=1, minmax=None):\n",
    "    df_exp[\"Label\"].replace({0: \"normal\", 1: \"attack\"}, inplace=True)\n",
    "    shap_exp = shap_all.values[:,df_exp.columns.get_loc(feature)]\n",
    "\n",
    "    mask = None\n",
    "    if trim == None:\n",
    "        mask = (np.abs(stats.zscore(df_exp[feature])) < 3)\n",
    "    else:\n",
    "        mask = (df_exp[feature] > trim[0]) & (df_exp[feature] < trim[1])\n",
    "\n",
    "    attack_outliers = shap_exp[~mask & (df_exp[\"Label\"] == \"attack\")]\n",
    "    normal_outliers = shap_exp[~mask & (df_exp[\"Label\"] == \"normal\")]\n",
    "\n",
    "    shap_exp = shap_exp[mask]\n",
    "    df_exp = df_exp[mask]\n",
    "\n",
    "    # plt.figure(dpi=200)\n",
    "    # plt.figure(80, y_squish)\n",
    "    # fig = plt.figure() \n",
    "    # ax = fig.add_axes([0, 0, 80, y_squish])\n",
    "    fig, ax = plt.subplots(dpi=200, figsize=(80, y_squish))\n",
    "    \n",
    "    cmap_name = \"icefire\"\n",
    "    violin_color = \"lightgray\"\n",
    "\n",
    "    scaler = max(abs(shap_exp.min()), abs(shap_exp.max()))\n",
    "    shap_hues = shap_exp / scaler\n",
    "    shap_hues = (shap_hues + 1) * shap_all.base_values[0]\n",
    "\n",
    "    if attack_outliers.size != 0:\n",
    "        attack_outliers /= max(abs(attack_outliers.min()), abs(attack_outliers.max()))\n",
    "        attack_outliers = (attack_outliers + 1) * shap_all.base_values[0]\n",
    "\n",
    "    if normal_outliers.size != 0:\n",
    "        normal_outliers /= max(abs(normal_outliers.min()), abs(normal_outliers.max()))\n",
    "        normal_outliers = (normal_outliers + 1) * shap_all.base_values[0]\n",
    "    \n",
    "    cmap = sns.color_palette(cmap_name, as_cmap=True)\n",
    "    norm = plt.Normalize(vmin=0, vmax=1)\n",
    "    palette = {h: cmap(h) for h in shap_hues}\n",
    "\n",
    "    values = df_exp[feature]\n",
    "    feature_min = values.min()\n",
    "    feature_max = values.max()\n",
    "    values = (values - values.min()) / (values.max() - values.min())\n",
    "    label = df_exp[\"Label\"]\n",
    "\n",
    "    sns.swarmplot(x=values, y=label, order=[\"normal\", \"attack\"],\n",
    "        hue=shap_hues, orient=\"h\", palette=palette,\n",
    "        size=5)\n",
    "    \n",
    "    # Change offset on dots for normal (0)\n",
    "    offsets = ax.collections[0].get_offsets()\n",
    "    offsets = [[elem[0], -abs(elem[1] - 0) - 0.05] for elem in offsets]\n",
    "    ax.collections[0].set_offsets(offsets)\n",
    "\n",
    "    # Change offset on dots for attack (1)\n",
    "    offsets = ax.collections[1].get_offsets()\n",
    "    offsets = [[elem[0], abs(elem[1] - 1) + 0.05] for elem in offsets]\n",
    "    ax.collections[1].set_offsets(offsets)\n",
    "\n",
    "    fig.set_size_inches(10, y_size)\n",
    "\n",
    "    sns.violinplot(x=values, y=[0]*label.size, hue=label, split=True, hue_order=[\"normal\", \"attack\"],\n",
    "        orient=\"h\",  showfliers=False, scale=\"count\", bw=0.2, gridsize=1000, linewidth=0, color=violin_color,\n",
    "        cut=0, inner=None)\n",
    "    \n",
    "    for violin in ax.findobj(matplotlib.collections.PolyCollection):\n",
    "        violin.set_facecolor(\"lightgray\")\n",
    "    \n",
    "    ax.legend_.remove()\n",
    "\n",
    "    if colorbar:\n",
    "        cbar = plt.colorbar(plt.cm.ScalarMappable(cmap=cmap_name), location=\"bottom\", shrink=0.4, anchor=(0.10, 0), pad=0.4)\n",
    "        cbar.set_label(\"contribution\", labelpad=-60)\n",
    "        cbar.set_ticks([0, 0.5, 1])\n",
    "        cbar.set_ticklabels([\"towards\\nnormal\", \"none\", \"towards\\nattack\"])\n",
    "\n",
    "        # plt.arrow(0, 0.5, 1, 0, facecolor=\"black\",\n",
    "        #     width=0.07, head_length=0.7, head_width=0.2,\n",
    "        #     length_includes_head=True)\n",
    "\n",
    "    # f_dict = {\"dcs\": \"A\", \"dcs_ID\": \"A\", \"dt\": \"C\", \"dt_ID\": \"B\", \"dt_data\": \"E\"}\n",
    "    # feature = f_dict[feature]\n",
    "    # ax.set_title(f\"How the RF-model classifies data - feature: {feature}\")\n",
    "    # ax.set_title(feature)\n",
    "    # feature = feature + \" (ms)\" if feature[0:2] == \"dt\" else feature\n",
    "\n",
    "    # ax.set_ylabel(\"type of data\")\n",
    "    ax.set_ylabel(feature) #, rotation=\"vertical\", x=-1, y=0.4)\n",
    "    # ax.set_xlabel(f\"value of {feature}\")\n",
    "    ax.set_xlabel(\"\")\n",
    "\n",
    "    if minmax == None:\n",
    "        ax.set_xticks(ticks=np.linspace(0, 1, 11), labels=map(lambda x: format(x*scale, '.2f'), np.linspace(minmax[0], minmax[1], 11)))\n",
    "    else:\n",
    "        ax.set_xticks(ticks=np.linspace(0, 1, 11), labels=map(lambda x: format(x*scale, '.2f'), np.linspace(minmax[0], minmax[1], 11)))\n",
    "    \n",
    "    ax.set_yticks(ticks=[-0.25, 0.25], labels=[\"normal\", \"attack\"])\n",
    "    ax.axhline(y=0, color=\"black\", linewidth=0.5)\n",
    "    \n",
    "    s_last = ax.get_xticks()[-2]\n",
    "    last = ax.get_xticks()[-1]\n",
    "    \n",
    "    largest_outliers = max(len(normal_outliers), len(attack_outliers))\n",
    "\n",
    "    if normal_outliers.size != 0:\n",
    "        # ax.text(last + (last-s_last) * 0.5, -0.28, f\"{len(normal_outliers)}\")\n",
    "        arrow_length = (last-s_last) * (len(normal_outliers) / largest_outliers)\n",
    "        ax.arrow(last + (last-s_last) * 0.5, -0.25, arrow_length, 0, facecolor=cmap(normal_outliers.mean()), edgecolor=violin_color,\n",
    "            width=0.07, head_length=(arrow_length)*0.7, head_width=0.2,\n",
    "            length_includes_head=True)\n",
    "    if attack_outliers.size != 0:\n",
    "        # ax.text(last + (last-s_last) * 0.5, 0.22, f\"{len(attack_outliers)}\")\n",
    "        arrow_length = (last-s_last) * (len(attack_outliers) / largest_outliers)\n",
    "        ax.arrow(last + (last-s_last) * 0.5, 0.25, arrow_length, 0, facecolor=cmap(attack_outliers.mean()), edgecolor=violin_color,\n",
    "            width=0.07, head_length=(arrow_length)*0.7, head_width=0.2,\n",
    "            length_includes_head=True)\n",
    "    \n",
    "    ax.margins(x=0.02)\n",
    "    \n",
    "    # return ax\n",
    "    plt.show()\n",
    "\n",
    "plot_test(pd.concat([X_exp_original, y_exp], axis=1), shap_all, \"dcs\", trim=(-1, 1), y_squish=25, minmax=(0, 1))\n",
    "plot_test(pd.concat([X_exp_original, y_exp], axis=1), shap_all, \"dcs_ID\", trim=(-1, 1), y_squish=15, minmax=(0, 1))\n",
    "plot_test(pd.concat([X_exp_original, y_exp], axis=1), shap_all, \"dt\", trim=(0, 0.0003), scale=1000, y_squish=15, minmax=(0, 0.0003))\n",
    "# plot_test(pd.concat([X_exp_original, y_exp], axis=1), shap_all, \"dt_ID\", trim=(0, 0.21), scale=1000)\n",
    "plot_test(pd.concat([X_exp_original, y_exp], axis=1), shap_all, \"dt_ID\", trim=(0, 0.02), scale=1000, minmax=(0, 0.02))\n",
    "plot_test(pd.concat([X_exp_original, y_exp], axis=1), shap_all, \"dt_data\", trim=(0, 0.02), scale=1000, colorbar=True, y_size=2.3, minmax=(0, 0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_exp(pd.concat([X_exp_original, y_exp], axis=1), shap_all, \"dt_ID\", trim=(0, 0.02), scale=1000)\n",
    "plot_exp(pd.concat([X_exp_original, y_exp], axis=1), shap_all, \"dt_data\", trim=(0, 0.02), scale=1000)\n",
    "plot_exp(pd.concat([X_exp_original, y_exp], axis=1), shap_all, \"dt\", trim=(0, 0.0003), scale=1000, y_squish=20)\n",
    "plot_exp(pd.concat([X_exp_original, y_exp], axis=1), shap_all, \"dcs\", trim=(-1, 0.7), y_squish=25)\n",
    "plot_exp(pd.concat([X_exp_original, y_exp], axis=1), shap_all, \"dcs_ID\", trim=(0, 1), y_squish=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_waterfall(shap_all, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_force(shap_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dependence(shap_all, \"dcs_ID\", \"dt_ID\", xmax=\"percentile(99)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_layer_1 = keras.Model(inputs=dnn.input, outputs=dnn.get_layer(\"layer_3\").output)\n",
    "\n",
    "dnn_layer_1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_layer_1 = shap.KernelExplainer(dnn_layer_1, data=X_train.sample(100, random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_all_layer_1 = get_explanation(exp_layer_1, X_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(shap_all_layer_1)\n",
    "shap.summary_plot(shap_all_layer_1, X_test, plot_type=\"bar\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cc1c01a394bbc3d069051c289161a3236732c38d026dbad3d7b5639e0cadb70"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ml-classify-pJEs0r8S-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
