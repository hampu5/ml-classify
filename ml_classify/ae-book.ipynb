{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "from timeit import timeit\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "# matplotlib.use(\"pgf\")\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from joblib import dump, load\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import shap\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compiledataset import load_dataset, compile_dataset\n",
    "\n",
    "PATH = \"/home/hampus/miun/master_thesis/Datasets\"\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "# dataset: pd.DataFrame = load_dataset(PATH + \"/ORNL\", \"data_a.csv\")\n",
    "# dataset[\"remarks\"] = \"No DLC available\"\n",
    "# datasets[\"ROAD\"] = dataset.to_dict(\"records\")\n",
    "\n",
    "dataset: pd.DataFrame = load_dataset(PATH + \"/Survival\", \"data.csv\")\n",
    "dataset[\"remarks\"] = \"-\"\n",
    "datasets[\"Survival\"] = dataset.to_dict(\"records\")\n",
    "\n",
    "# dataset: pd.DataFrame = load_dataset(PATH + \"/Hisingen\", \"data.csv\")\n",
    "# dataset[\"remarks\"] = \"-\"\n",
    "# datasets[\"Hisingen\"] = dataset.to_dict(\"records\")\n",
    "\n",
    "\n",
    "df = compile_dataset(datasets)\n",
    "df.drop(columns=[\"data\", \"data_dec\", \"ID\", \"DLC\", \"t\"], inplace=True, errors=\"ignore\")\n",
    "# df.drop(columns=[\"d0\", \"d1\", \"d2\", \"d3\", \"d4\", \"d5\", \"d6\", \"d7\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "dataset = None # Release memory, as it isn't used for now\n",
    "datasets = None\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "feature_columns= list(set(df.columns.to_list()).difference([\"name\", \"class\", \"dataset\", \"type\", \"Label\"]))\n",
    "\n",
    "for col in feature_columns:\n",
    "    scaler = RobustScaler().fit(df.loc[df[\"Label\"] == 0, df.columns == col])\n",
    "    df.loc[:, df.columns ==col] = scaler.transform(df.loc[:, df.columns == col])\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratify on the sub-dataset\n",
    "X_train = df.drop(columns=\"Label\")\n",
    "y_train = df[\"Label\"]\n",
    "\n",
    "df = None # Release memory\n",
    "\n",
    "# Split dataset into training and test data, stratify by the type of attack\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.3, random_state=0, shuffle=True, stratify=X_train[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=[\"type\", \"dataset\", \"name\", \"class\"], inplace=True)\n",
    "X_test.drop(columns=[\"type\", \"dataset\", \"name\", \"class\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = df.loc[df[\"Label\"] == 0]\n",
    "# X_test = df.loc[df[\"Label\"] == 1]\n",
    "X_train_normal = X_train.loc[y_train[y_train == 0].index]\n",
    "X_train_anomaly = X_train.loc[y_train[y_train == 1].index]\n",
    "\n",
    "X_test_normal = X_test.loc[y_test[y_test == 0].index]\n",
    "X_test_anomaly = X_test.loc[y_test[y_test == 1].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_train_normal.iloc[0])\n",
    "plt.plot(X_train_normal.iloc[1])\n",
    "plt.plot(X_train_normal.iloc[2])\n",
    "plt.title(\"Normal Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_train_anomaly.iloc[0])\n",
    "plt.plot(X_train_anomaly.iloc[1])\n",
    "plt.plot(X_train_anomaly.iloc[2])\n",
    "plt.title(\"Anomaly Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential, layers, callbacks\n",
    "from keras.models import Model\n",
    "\n",
    "class AutoEncoder(Model):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = Sequential([ # 13 input features\n",
    "            layers.Dense(10, activation=\"relu\"),\n",
    "            layers.Dense(7, activation=\"relu\"),\n",
    "            layers.Dense(5, activation=\"relu\"),\n",
    "            layers.Dense(2, activation=\"relu\")\n",
    "        ])\n",
    "        self.decoder = Sequential([\n",
    "            layers.Dense(5, activation=\"relu\"),\n",
    "            layers.Dense(7, activation=\"relu\"),\n",
    "            layers.Dense(10, activation=\"relu\"),\n",
    "            layers.Dense(13, activation=\"sigmoid\")\n",
    "        ])\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# input_img = keras.Input(shape=(6,))\n",
    "# encoded = layers.Dense(4, activation='relu')(input_img)\n",
    "# encoded = layers.Dense(2, activation='relu')(encoded)\n",
    "# encoded = layers.Dense(1, activation='relu')(encoded)\n",
    "\n",
    "# decoded = layers.Dense(2, activation='relu')(encoded)\n",
    "# decoded = layers.Dense(4, activation='relu')(decoded)\n",
    "# decoded = layers.Dense(6, activation='sigmoid')(decoded)\n",
    "\n",
    "# autoencoder = keras.Model(input_img, decoded)\n",
    "# autoencoder.compile(optimizer='adam', loss='msle')\n",
    "\n",
    "model = AutoEncoder()\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001,\n",
    "    patience=10,\n",
    "    verbose=1, \n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss=\"mean_squared_error\")\n",
    "history = model.fit(X_train_normal, X_train_normal, epochs=25, batch_size=120,\n",
    "    validation_data=(X_test_normal, X_test_normal),\n",
    "    shuffle=True,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# history = autoencoder.fit(X_train, X_train,\n",
    "#     epochs=100,\n",
    "#     batch_size=256,\n",
    "#     shuffle=True,\n",
    "#     validation_data=(X_test, X_test),\n",
    "#     callbacks=[early_stop]\n",
    "# ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], linewidth=2, label='Train')\n",
    "plt.plot(history.history['val_loss'], linewidth=2, label='Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "#plt.ylim(ymin=0.70,ymax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pred = model.predict(X_test)\n",
    "mse = np.mean(np.power(X_test - X_test_pred, 2), axis=1)\n",
    "error_df = pd.DataFrame({'Reconstruction_error': mse, 'True_class': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_fixed = 50\n",
    "groups = error_df.groupby('True_class')\n",
    "fig, ax = plt.subplots()\n",
    "for name, group in groups:\n",
    "    ax.plot(group.index, group.Reconstruction_error, marker='o', ms=3.5, linestyle='',\n",
    "            label= \"Fraud\" if name == 1 else \"Normal\")\n",
    "ax.hlines(threshold_fixed, ax.get_xlim()[0], ax.get_xlim()[1], colors=\"r\", zorder=100, label='Threshold')\n",
    "ax.legend()\n",
    "ax.set_yscale('log')\n",
    "plt.title(\"Reconstruction error for normal and fraud data\")\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.xlabel(\"Data point index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_tools import plot_confusion_matrix\n",
    "\n",
    "threshold_fixed = 52\n",
    "y_pred = [1 if e > threshold_fixed else 0 for e in error_df.Reconstruction_error.values]\n",
    "error_df['pred'] = y_pred\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred, \"Confusion matrix for the Autoencoder\")\n",
    "\n",
    "f1_scores = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"Testing F1:  %0.4f(+/- %0.4f)\" % (f1_scores.mean(), f1_scores.std()))\n",
    "\n",
    "kappa_scores = cohen_kappa_score(y_test, y_pred)\n",
    "print(\"Kappa score:  %0.4f(+/- %0.4f)\" % (kappa_scores.mean(), kappa_scores.std()))\n",
    "\n",
    "# # print Accuracy, precision and recall\n",
    "# print(\" Accuracy: \",accuracy_score(error_df['True_class'], error_df['pred']))\n",
    "# print(\" Recall: \",recall_score(error_df['True_class'], error_df['pred']))\n",
    "# print(\" Precision: \",precision_score(error_df['True_class'], error_df['pred']))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cc1c01a394bbc3d069051c289161a3236732c38d026dbad3d7b5639e0cadb70"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ml-classify-pJEs0r8S-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
