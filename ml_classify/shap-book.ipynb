{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "from timeit import timeit\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from joblib import dump, load\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df: pd.DataFrame = load(\"dumped_datasets/survival_all.joblib\")\n",
    "df: pd.DataFrame = load(\"dumped_datasets/road_all.joblib\")\n",
    "# df: pd.DataFrame = load(\"dumped_datasets/hisingen_all.joblib\")\n",
    "\n",
    "df.drop(columns=[\"data\", \"data_dec\", \"ID\", \"DLC\", \"t\"], inplace=True, errors=\"ignore\")\n",
    "df.drop(columns=[\"d0\", \"d1\", \"d2\", \"d3\", \"d4\", \"d5\", \"d6\", \"d7\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratify on the sub-dataset\n",
    "X_train = df.drop(columns=\"Label\")\n",
    "y_train = df[\"Label\"]\n",
    "\n",
    "df = None # Release memory\n",
    "\n",
    "# Split dataset into training and test data, stratify by the type of attack\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.3, random_state=0, shuffle=True, stratify=X_train[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rus = RandomUnderSampler(random_state=0)\n",
    "# X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "# X_test, y_test = rus.fit_resample(X_test, y_test)\n",
    "# bintr = np.bincount(y_train)\n",
    "# binte = np.bincount(y_test)\n",
    "# print(f\"Labels\\t\\tTraining\\tTesting\\nNormal\\t\\t{bintr[0]}\\t\\t{binte[0]}\\nAttack\\t\\t{bintr[1]}\\t\\t{binte[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_train = X_train[\"name\"]\n",
    "# name_test = X_test[\"name\"]\n",
    "X_train.drop(columns=[\"type\", \"dataset\", \"name\", \"class\"], inplace=True)\n",
    "X_test.drop(columns=[\"type\", \"dataset\", \"name\", \"class\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pp_tools import scale_dataset\n",
    "\n",
    "X_train_original = X_train.copy()\n",
    "X_test_original = X_test.copy()\n",
    "\n",
    "X_combined = pd.concat([X_train, X_test])\n",
    "\n",
    "scale_dataset(X_combined)\n",
    "\n",
    "test_len = len(X_test)\n",
    "X_test = X_combined.iloc[-test_len:]\n",
    "X_train = X_combined.iloc[:-test_len]\n",
    "\n",
    "X_combined = None # Release memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vvv RF vvv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=20, random_state=0, max_leaf_nodes=300, max_features=\"log2\", warm_start=True)\n",
    "rf.fit(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vvv DNN vvv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "dnn = keras.models.load_model(\"dnn_all_road_imbalanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vvv SHAP vvv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import tensorflow as tf\n",
    "\n",
    "X_sample = pd.concat([X_train[y_train == 1].sample(50, random_state=0), X_train[y_train == 0].sample(50, random_state=0)]).values\n",
    "\n",
    "# vvv RF vvv\n",
    "\n",
    "exp_rf = shap.KernelExplainer(rf.predict_proba, data=X_sample, algorithm=\"kernel\")\n",
    "exp_rf_tree = shap.TreeExplainer(rf)\n",
    "\n",
    "# vvv DNN vvv\n",
    "\n",
    "exp_dnn = shap.KernelExplainer(dnn.predict, data=X_sample, algorithm=\"kernel\")\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "exp_dnn_deep = shap.DeepExplainer((dnn.layers[0].input, dnn.layers[-1].output), data=X_sample)\n",
    "exp_dnn_grad = shap.GradientExplainer((dnn.layers[0].input, dnn.layers[-1].output), data=X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shap_tools import *\n",
    "\n",
    "max_samples = int(min(len(X_train), 600) / 2)\n",
    "\n",
    "X_exp = pd.concat([X_train[y_train == 1].sample(max_samples, random_state=0), X_train[y_train == 0].sample(max_samples, random_state=0)])\n",
    "# X_exp = X_train.sample(min(len(X_train), 600), random_state=0)\n",
    "y_exp = y_train[X_exp.index]\n",
    "X_exp_original = X_train_original.loc[X_exp.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_explanation2(explainer, df: pd.DataFrame):\n",
    "    return shap.Explanation(\n",
    "        values=explainer.shap_values(df.values)[-1],\n",
    "        base_values=0.5, #explainer.expected_value[-1],\n",
    "        data=df.to_numpy(),\n",
    "        feature_names=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_rf = get_explanation2(exp_rf, X_exp)\n",
    "shap_rf_tree = get_explanation2(exp_rf_tree, X_exp)\n",
    "\n",
    "shap_dnn = get_explanation2(exp_dnn, X_exp)\n",
    "shap_dnn_deep = get_explanation2(exp_dnn_deep, X_exp)\n",
    "shap_dnn_grad = get_explanation2(exp_dnn_grad, X_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_beeswarm2(exp_obj):\n",
    "    cbar = plt.colorbar(plt.cm.ScalarMappable(cmap=\"plasma\"), label=\"Feature value\")\n",
    "    cbar.set_ticks([0, 1])\n",
    "    cbar.set_ticklabels([\"Low\", \"High\"])\n",
    "    vis = shap.plots.beeswarm(exp_obj, max_display=20, color=plt.get_cmap(\"plasma\"), color_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_beeswarm2(shap_rf)\n",
    "plot_beeswarm2(shap_rf_tree)\n",
    "plot_beeswarm2(shap_dnn)\n",
    "plot_beeswarm2(shap_dnn_deep)\n",
    "plot_beeswarm2(shap_dnn_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.summary_plot(shap_rf, plot_type=\"bar\")\n",
    "# shap.summary_plot(shap_rf_tree, plot_type=\"bar\")\n",
    "# shap.summary_plot(shap_dnn, plot_type=\"bar\")\n",
    "# shap.summary_plot(shap_dnn_deep, plot_type=\"bar\")\n",
    "# shap.summary_plot(shap_dnn_grad, plot_type=\"bar\")\n",
    "\n",
    "tata = pd.DataFrame([shap_rf, shap_rf_tree, shap_dnn, shap_dnn_deep, shap_dnn_grad])\n",
    "\n",
    "# sns.barplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclid(a, b):\n",
    "    return np.sqrt(np.dot(b-a, b-a))\n",
    "\n",
    "def cosim(a, b):\n",
    "    return np.dot(a, b)/(np.sqrt(np.dot(a, a)) * np.sqrt(np.dot(b, b)))\n",
    "\n",
    "shap_rf_avg = np.array(shap_rf.values).flatten() # np.mean(shap_rf.values, axis=0)\n",
    "shap_dnn_avg = np.array(shap_dnn.values).flatten() # np.mean(shap_dnn.values, axis=0)\n",
    "\n",
    "# print(shap_rf_avg)\n",
    "# print(shap_dnn_avg)\n",
    "\n",
    "# shap_cosims = np.sort(list(map(cosim, shap_rf.values, shap_rf_tree.values)))\n",
    "# shap_cosims = list(map(cosim, shap_rf.values, shap_rf_tree.values))\n",
    "\n",
    "all_shaps = [shap_rf, shap_rf_tree, shap_dnn, shap_dnn_deep, shap_dnn_grad]\n",
    "names = [\"RF_KernelExplainer\", \"RF_TreeExplainer\", \"DNN_KernelExplainer\", \"DNN_DeepExplainer\", \"DNN_GradientExplainer\"]\n",
    "\n",
    "temp = pd.DataFrame(index=names, columns=names, dtype=np.float64)\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        temp.iloc[i, j] = np.mean(list(map(cosim, all_shaps[i].values, all_shaps[j].values)))\n",
    "\n",
    "# Drop first row and last column that don't provide information\n",
    "temp.drop(index=temp.index[0], inplace=True)\n",
    "temp.drop(columns=temp.columns[-1], inplace=True)\n",
    "\n",
    "# Generate a mask for the upper triangle but not the diagonal\n",
    "mask = np.triu(np.ones_like(temp, dtype=bool))\n",
    "np.fill_diagonal(mask, False)\n",
    "\n",
    "sns.heatmap(temp, annot=True, square=True, mask=mask, vmin=0.7, vmax=1, center=0.7, annot_kws={\"fontsize\": 12}, fmt=\".3f\")\n",
    "plt.xticks(rotation=20, horizontalalignment=\"right\")\n",
    "\n",
    "# print(np.mean(shap_cosims))\n",
    "# print(euclid(shap_rf_avg, shap_dnn_avg))\n",
    "# plt.plot(shap_cosims)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cc1c01a394bbc3d069051c289161a3236732c38d026dbad3d7b5639e0cadb70"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ml-classify-pJEs0r8S-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
